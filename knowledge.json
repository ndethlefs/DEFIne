{"occupancy_test.txt": {"learning_rate": "(length_scale=4)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=4)", "input_features": "(length_scale=5)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=1)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=10)", "layers": "(length_scale=2)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=1)", "hidden_size": "(length_scale=3)", "search": "(length_scale=10)", "normalised": "[[  7.70737389e-05   5.39516172e-04   1.54147478e-04   7.70737389e-05\n    2.05401514e-01   7.34743953e-01   3.51620626e-01   3.27100948e-01\n    2.09974080e-01   3.78470595e-01   1.20040948e-05  -9.17051914e-05\n    7.70737389e-05]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=9)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=7)", "data_type": "(length_scale=8)", "loss": "(length_scale=1)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=4)", "optimiser": "(length_scale=5)", "epochs": "(length_scale=10)", "activation2": "(length_scale=2)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=9)"}, "UCI_HAR_train.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=8)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=1)", "hardware": "(length_scale=1)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=6)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=3)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=6)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=2)", "search": "(length_scale=8)", "normalised": "[[  1.35623096e-04   7.60845570e-02   8.13738577e-04   0.00000000e+00\n    9.97101003e-01   0.00000000e+00  -6.89460404e-05  -9.58138570e-05\n    7.19988244e-05   1.19408924e-04   1.17485247e-04  -3.99311188e-05\n    0.00000000e+00]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=3)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=6)", "loss": "(length_scale=9)", "score": "(length_scale=4)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=2)", "activation2": "(length_scale=9)", "activation1": "(length_scale=7)", "search_algorithm": "(length_scale=2)"}, "japanese_credit_screening.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=2)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=4)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=3)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=1)", "search": "(length_scale=6)", "normalised": "[[  6.55596014e-04   9.83394021e-03   1.31119203e-03   6.55596014e-04\n    4.52361250e-01   6.35272538e-01   3.50246881e-01   3.46810291e-01\n    1.87601830e-01   3.36976351e-01  -6.23840442e-05  -7.87200590e-04\n    6.55596014e-04]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=8)", "dimensionality": "(length_scale=4)", "data_type": "(length_scale=10)", "loss": "(length_scale=10)", "score": "(length_scale=1)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=9)", "search_algorithm": "(length_scale=9)"}, "pima_indians_diabetes.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=1)", "input_features": "(length_scale=6)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=5)", "momentum": "(length_scale=5)", "modelString": "(length_scale=10)", "init_mode": "(length_scale=8)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=6)", "search": "(length_scale=4)", "normalised": "[[ 0.0012897   0.01031757  0.00257939  0.          0.99048698  0.\n   0.05801802  0.03727223  0.07528342  0.08640967  0.0043716   0.03017381\n   0.0012897 ]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=10)", "loss": "(length_scale=3)", "score": "(length_scale=3)", "size_of_datasets": "(length_scale=8)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=4)", "activation2": "(length_scale=4)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=4)"}, "cervical_cancer.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=1)", "hardware": "(length_scale=2)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=1)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=5)", "layers": "(length_scale=9)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=3)", "search": "(length_scale=4)", "normalised": "[[  1.14568624e-03   4.00990185e-02   2.29137249e-03   1.14568624e-03\n    9.82998797e-01   1.64978819e-01   3.86224834e-02   2.86421561e-02\n    3.60938049e-02   3.55162735e-02   1.61184985e-03   8.43939618e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=6)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=10)", "dimensionality": "(length_scale=7)", "data_type": "(length_scale=9)", "loss": "(length_scale=10)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=4)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=2)", "activation2": "(length_scale=2)", "activation1": "(length_scale=7)", "search_algorithm": "(length_scale=4)"}, "contraception_choice.txt": {"learning_rate": "(length_scale=3)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=10)", "input_features": "(length_scale=1)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=3)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=5)", "layers": "(length_scale=1)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=1)", "hidden_size": "(length_scale=6)", "search": "(length_scale=6)", "normalised": "[[  6.78842471e-04   6.10958224e-03   2.03652741e-03   0.00000000e+00\n    9.99934960e-01   0.00000000e+00   3.70600777e-03   1.35768494e-03\n    6.84222473e-03   2.03652741e-03   1.84122557e-03   4.26711691e-03\n    0.00000000e+00]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=10)", "loss": "(length_scale=5)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=6)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=7)"}, "glass.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=10)", "input_features": "(length_scale=2)", "hardware": "(length_scale=10)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=4)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=2)", "layers": "(length_scale=2)", "dropout_rate": "(length_scale=2)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=7)", "search": "(length_scale=1)", "normalised": "[[ 0.00455296  0.04552955  0.02731773  0.          0.97433247  0.\n   0.0951079   0.00796767  0.18530695  0.05795912  0.01168701  0.02987995\n   0.        ]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=4)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=9)", "loss": "(length_scale=9)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=2)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=6)"}, "mammographic_mass.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=8)", "vocab_size": "(length_scale=4)", "input_features": "(length_scale=3)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=4)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=8)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=10)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=2)", "search": "(length_scale=4)", "normalised": "[[  1.03256105e-03   5.16280526e-03   2.06512210e-03   1.03256105e-03\n    9.92291170e-01   8.57025673e-02   4.04506060e-02   2.27163431e-02\n    2.98970413e-02   7.02141515e-02   2.80218583e-04  -1.72132138e-03\n    1.03256105e-03]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=6)", "loss": "(length_scale=7)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=10)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=7)"}, "soybean.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=4)", "vocab_size": "(length_scale=10)", "input_features": "(length_scale=6)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=9)", "modelString": "(length_scale=10)", "init_mode": "(length_scale=8)", "layers": "(length_scale=1)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=9)", "search": "(length_scale=4)", "normalised": "[[ 0.003199    0.11196496  0.012796    0.003199    0.98209266  0.09277097\n   0.06153689  0.07997497  0.02551915  0.05758198 -0.00285378 -0.00305812\n   0.        ]]", "cpu_cores": "(length_scale=7)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=3)", "data_type": "(length_scale=6)", "loss": "(length_scale=4)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=6)", "activation2": "(length_scale=3)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=3)"}, "australian_credit_approval.txt": {"learning_rate": "(length_scale=7)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=4)", "vocab_size": "(length_scale=10)", "input_features": "(length_scale=7)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=7)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=8)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=3)", "hidden_size": "(length_scale=6)", "search": "(length_scale=6)", "normalised": "[[  2.99825049e-04   4.19755068e-03   5.99650097e-04   0.00000000e+00\n    2.06879283e-01   0.00000000e+00   2.70099142e-02   5.99650097e-04\n    4.24728639e-01   1.94886282e-03   1.45152105e-02   8.80820125e-01\n    0.00000000e+00]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=4)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=5)", "loss": "(length_scale=6)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=6)"}, "german_credit_data.txt": {"learning_rate": "(length_scale=7)", "learning_tasks": "(length_scale=4)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=2)", "hardware": "(length_scale=10)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=10)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=4)", "layers": "(length_scale=10)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=2)", "search": "(length_scale=2)", "normalised": "[[  5.92535593e-04   1.18507119e-02   1.18507119e-03   5.92535593e-04\n    5.92535593e-01   6.20977302e-01   3.00365269e-01   2.81454407e-01\n    1.59460151e-01   2.61308197e-01   7.94220303e-05  -6.83364230e-04\n    5.92535593e-04]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=4)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=4)", "loss": "(length_scale=5)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=10)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=9)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=1)"}, "occupancy_train.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=4)", "hardware": "(length_scale=9)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=10)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=7)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=4)", "search": "(length_scale=7)", "normalised": "[[  3.10147924e-05   2.17103547e-04   6.20295848e-05   3.10147924e-05\n    2.52553455e-01   7.22396545e-01   3.28231860e-01   3.23329211e-01\n    2.17206303e-01   3.93577716e-01   3.91027016e-06  -3.94460018e-05\n    3.10147924e-05]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=8)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=2)", "loss": "(length_scale=9)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=4)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=4)"}, "musk.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=3)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=3)", "hardware": "(length_scale=9)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=4)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=9)", "layers": "(length_scale=2)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=10)", "search": "(length_scale=9)", "normalised": "[[  5.70642393e-04   9.58679221e-02   1.14128479e-03   5.70642393e-04\n    2.71625779e-01   6.86482799e-01   3.60809140e-01   3.80618476e-01\n    2.04646914e-01   3.58934065e-01  -7.63130205e-05  -7.08521583e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=2)", "batch_size": "(length_scale=5)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=7)", "loss": "(length_scale=5)", "score": "(length_scale=4)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=6)", "activation2": "(length_scale=2)", "activation1": "(length_scale=1)", "search_algorithm": "(length_scale=7)"}, "car.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=6)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=2)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=8)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=7)", "hidden_size": "(length_scale=2)", "search": "(length_scale=5)", "normalised": "[[  5.78630224e-04   3.47178134e-03   2.31452090e-03   5.78630224e-04\n    9.99873027e-01   1.21512347e-02   6.14794613e-03   5.78630224e-03\n    2.84033105e-03   2.89315112e-03  -1.12429704e-05  -3.82209383e-04\n    5.78630224e-04]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=2)", "loss": "(length_scale=9)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=2)", "optimiser": "(length_scale=6)", "epochs": "(length_scale=8)", "activation2": "(length_scale=3)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=9)"}, "hypo_thyroid.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=4)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=4)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=8)", "modelString": "(length_scale=2)", "init_mode": "(length_scale=1)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=10)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=9)", "search": "(length_scale=5)", "normalised": "[[  3.04020398e-04   7.60050996e-03   1.61130811e-02   3.04020398e-04\n    9.61616520e-01   1.75723790e-01   1.26302715e-01   1.40761445e-01\n    4.91390407e-02   7.69171608e-02  -2.17036806e-04  -1.96466498e-04\n    3.04020398e-04]]", "cpu_cores": "(length_scale=6)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=1)", "dimensionality": "(length_scale=5)", "data_type": "(length_scale=10)", "loss": "(length_scale=9)", "score": "(length_scale=1)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=6)", "epochs": "(length_scale=6)", "activation2": "(length_scale=2)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=9)"}, "parkinsons.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=2)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=8)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=7)", "modelString": "(length_scale=9)", "init_mode": "(length_scale=7)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=2)", "search": "(length_scale=8)", "normalised": "[[  2.05333862e-04   4.72267883e-03   4.02454370e-02   2.05333862e-04\n    4.02454370e-02   7.38175234e-01   3.72418007e-01   3.67958281e-01\n    2.12800999e-01   3.63954271e-01  -1.77812527e-06  -2.41332302e-04\n    2.05333862e-04]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=4)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=8)", "loss": "(length_scale=5)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=2)", "optimiser": "(length_scale=4)", "epochs": "(length_scale=6)", "activation2": "(length_scale=2)", "activation1": "(length_scale=1)", "search_algorithm": "(length_scale=1)"}, "sponge.txt": {"learning_rate": "(length_scale=3)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=1)", "input_features": "(length_scale=7)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=8)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=4)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=7)", "search": "(length_scale=5)", "normalised": "[[ 0.00340621  0.15327935  0.01021862  0.00340621  0.25887179  0.66421051\n   0.35093202  0.43599459  0.19723211  0.34062078 -0.00123058 -0.00430121\n   0.        ]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=6)", "loss": "(length_scale=10)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=5)", "epochs": "(length_scale=6)", "activation2": "(length_scale=2)", "activation1": "(length_scale=9)", "search_algorithm": "(length_scale=7)"}, "fertility.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=4)", "vocab_size": "(length_scale=1)", "input_features": "(length_scale=9)", "hardware": "(length_scale=9)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=7)", "modelString": "(length_scale=9)", "init_mode": "(length_scale=1)", "layers": "(length_scale=2)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=5)", "hidden_size": "(length_scale=5)", "search": "(length_scale=3)", "normalised": "[[ 0.00995547  0.08959924  0.01991094  0.          0.99554715  0.\n   0.00385929  0.00557506  0.0063175   0.00995547 -0.00855169 -0.00224898\n   0.00995547]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=10)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=10)", "loss": "(length_scale=9)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=9)", "activation2": "(length_scale=2)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=2)"}, "seismic_bumps.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=2)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=3)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=10)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=8)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=2)", "output_features": "(length_scale=7)", "hidden_size": "(length_scale=5)", "search": "(length_scale=2)", "normalised": "[[  1.60457958e-04   2.88824324e-03   3.20915916e-04   1.60457958e-04\n    4.14623363e-01   5.81018266e-01   4.00669810e-01   4.99986997e-01\n    1.50785517e-01   2.39242815e-01  -1.32918214e-04  -1.04013823e-04\n    1.60457958e-04]]", "cpu_cores": "(length_scale=7)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=8)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=6)", "loss": "(length_scale=10)", "score": "(length_scale=6)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=2)", "activation2": "(length_scale=2)", "activation1": "(length_scale=5)", "search_algorithm": "(length_scale=6)"}, "soybeans.txt": {"learning_rate": "(length_scale=7)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=9)", "input_features": "(length_scale=8)", "hardware": "(length_scale=2)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=2)", "modelString": "(length_scale=9)", "init_mode": "(length_scale=1)", "layers": "(length_scale=10)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=1)", "search": "(length_scale=3)", "normalised": "[[ 0.003199    0.11196496  0.012796    0.003199    0.98209266  0.09277097\n   0.06153689  0.07997497  0.02551915  0.05758198 -0.00285378 -0.00305812\n   0.        ]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=7)", "weight_constraint": "(length_scale=8)", "dimensionality": "(length_scale=8)", "data_type": "(length_scale=5)", "loss": "(length_scale=4)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=6)", "epochs": "(length_scale=9)", "activation2": "(length_scale=4)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=9)"}, "urban_land_cover_test.txt": {"learning_rate": "(length_scale=10)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=1)", "input_features": "(length_scale=7)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=4)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=1)", "layers": "(length_scale=9)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=8)", "search": "(length_scale=9)", "normalised": "[[  6.12879589e-04   9.00932996e-02   5.51591630e-03   0.00000000e+00\n    3.10729952e-01   0.00000000e+00   2.05935681e-01   4.28402833e-03\n    9.04841950e-01   9.08164975e-02   7.93928946e-03   1.60691670e-01\n    0.00000000e+00]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=5)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=2)", "data_type": "(length_scale=5)", "loss": "(length_scale=7)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=10)", "optimiser": "(length_scale=4)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=6)"}, "processed.cleveland.data-out.txt": {"learning_rate": "(length_scale=4)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=10)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=8)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=10)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=6)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=4)", "search": "(length_scale=4)", "normalised": "[[  3.36360737e-03   4.37268958e-02   6.72721473e-03   0.00000000e+00\n    9.98991388e-01   0.00000000e+00   1.70453794e-03   1.83469493e-03\n    1.24420861e-03   2.71419802e-03  -4.21867966e-04  -4.57359779e-03\n    3.36360737e-03]]", "cpu_cores": "(length_scale=6)", "batch_size": "(length_scale=1)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=1)", "loss": "(length_scale=7)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=1)", "activation2": "(length_scale=10)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=5)"}, "nomao.txt": {"learning_rate": "(length_scale=4)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=8)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=6)", "modelString": "(length_scale=10)", "init_mode": "(length_scale=1)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=6)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=7)", "search": "(length_scale=4)", "normalised": "[[  6.80155105e-06   8.09384575e-04   1.36031021e-05   6.80155105e-06\n    2.34415457e-01   6.73618814e-01   2.97385475e-01   2.18506629e-01\n    2.41229036e-01   5.44896060e-01   3.09535727e-06  -8.70136908e-06\n    0.00000000e+00]]", "cpu_cores": "(length_scale=7)", "batch_size": "(length_scale=1)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=4)", "loss": "(length_scale=4)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=7)", "epochs": "(length_scale=7)", "activation2": "(length_scale=2)", "activation1": "(length_scale=1)", "search_algorithm": "(length_scale=6)"}, "htru_2.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=3)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=2)", "input_features": "(length_scale=1)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=9)", "momentum": "(length_scale=7)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=4)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=5)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=2)", "search": "(length_scale=2)", "normalised": "[[  5.58713912e-05   4.46971129e-04   1.11742782e-04   0.00000000e+00\n    9.99986159e-01   0.00000000e+00   2.17884329e-03   7.24657836e-04\n    3.28262787e-03   2.84911741e-03   2.13096523e-04   1.80347756e-03\n    5.58713912e-05]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=5)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=5)", "data_type": "(length_scale=7)", "loss": "(length_scale=6)", "score": "(length_scale=1)", "size_of_datasets": "(length_scale=8)", "optimiser": "(length_scale=3)", "epochs": "(length_scale=2)", "activation2": "(length_scale=2)", "activation1": "(length_scale=1)", "search_algorithm": "(length_scale=4)"}, "annealing_train.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=10)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=5)", "momentum": "(length_scale=2)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=9)", "layers": "(length_scale=10)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=3)", "search": "(length_scale=6)", "normalised": "[[  1.19385809e-03   4.53666074e-02   5.96929044e-03   1.19385809e-03\n    9.52698755e-01   2.20863746e-01   1.31459587e-01   1.49232261e-01\n    4.26332346e-02   1.07447228e-02  -1.37994587e-03   9.15941350e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=1)", "weight_constraint": "(length_scale=10)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=9)", "loss": "(length_scale=4)", "score": "(length_scale=1)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=4)", "activation2": "(length_scale=7)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=3)"}, "digital_colposcopy_green.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=4)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=1)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=6)", "momentum": "(length_scale=6)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=10)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=10)", "output_features": "(length_scale=1)", "hidden_size": "(length_scale=7)", "search": "(length_scale=3)", "normalised": "[[ 0.00700856  0.47658234  0.01401713  0.          0.68683926  0.\n   0.23169087  0.02060754  0.37974214  0.31785281  0.01518401  0.03612651\n   0.        ]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=5)", "data_type": "(length_scale=10)", "loss": "(length_scale=6)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=9)", "activation2": "(length_scale=1)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=4)"}, "cargo2000_freight_tracking.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=9)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=4)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=6)", "momentum": "(length_scale=9)", "modelString": "(length_scale=5)", "init_mode": "(length_scale=6)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=10)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=8)", "search": "(length_scale=3)", "normalised": "[[  5.79365445e-05   5.61984482e-03   1.73809633e-04   5.79365445e-05\n    2.28385858e-01   8.15167181e-01   3.75856938e-01   3.30585923e-01\n    1.65455052e-01   7.33476653e-02   4.34543957e-05   3.34341220e-05\n    0.00000000e+00]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=1)", "loss": "(length_scale=6)", "score": "(length_scale=3)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=9)", "search_algorithm": "(length_scale=6)"}, "wilt_test.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=2)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=8)", "hardware": "(length_scale=2)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=9)", "modelString": "(length_scale=2)", "init_mode": "(length_scale=10)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=1)", "hidden_size": "(length_scale=8)", "search": "(length_scale=2)", "normalised": "[[ 0.00169703  0.00848513  0.00339405  0.          0.8485127   0.\n   0.31189593  0.22230471  0.28898408  0.22247633  0.00365816  0.01475036\n   0.00169703]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=1)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=5)", "loss": "(length_scale=5)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=10)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=1)"}, "bank-full.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=8)", "vocab_size": "(length_scale=7)", "input_features": "(length_scale=3)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=5)", "modelString": "(length_scale=5)", "init_mode": "(length_scale=4)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=2)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=4)", "search": "(length_scale=5)", "normalised": "[[  2.16434020e-05   3.46294432e-04   4.32868040e-05   2.16434020e-05\n    9.78519847e-01   1.56395223e-01   7.44320375e-02   8.10761838e-02\n    3.99592085e-02   6.57959420e-02   2.98537428e-06  -2.18695730e-05\n    2.16434020e-05]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=2)", "loss": "(length_scale=5)", "score": "(length_scale=6)", "size_of_datasets": "(length_scale=2)", "optimiser": "(length_scale=5)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=3)"}, "thoraric_surgery.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=2)", "vocab_size": "(length_scale=7)", "input_features": "(length_scale=2)", "hardware": "(length_scale=10)", "fit_time": "(length_scale=5)", "momentum": "(length_scale=1)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=6)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=2)", "search": "(length_scale=1)", "normalised": "[[ 0.00179881  0.02878099  0.00359762  0.00179881  0.84544158  0.46229465\n   0.18402635  0.17448475  0.07795506  0.01618931  0.00174474  0.00290719\n   0.00179881]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=1)", "dimensionality": "(length_scale=5)", "data_type": "(length_scale=9)", "loss": "(length_scale=10)", "score": "(length_scale=1)", "size_of_datasets": "(length_scale=10)", "optimiser": "(length_scale=3)", "epochs": "(length_scale=7)", "activation2": "(length_scale=2)", "activation1": "(length_scale=9)", "search_algorithm": "(length_scale=3)"}, "cover_type.txt": {"learning_rate": "(length_scale=3)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=4)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=5)", "hardware": "(length_scale=10)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=1)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=1)", "layers": "(length_scale=1)", "dropout_rate": "(length_scale=2)", "output_features": "(length_scale=7)", "hidden_size": "(length_scale=6)", "search": "(length_scale=5)", "normalised": "[[  1.72113376e-06   9.29412232e-05   1.20479363e-05   0.00000000e+00\n    9.99999370e-01   0.00000000e+00   2.66310509e-04   0.00000000e+00\n    1.08477975e-03   0.00000000e+00   8.98048581e-06   5.14942417e-05\n    0.00000000e+00]]", "cpu_cores": "(length_scale=4)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=7)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=9)", "loss": "(length_scale=8)", "score": "(length_scale=4)", "size_of_datasets": "(length_scale=3)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=7)", "activation2": "(length_scale=2)", "activation1": "(length_scale=1)", "search_algorithm": "(length_scale=6)"}, "eeg_eyes.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=4)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=3)", "hardware": "(length_scale=1)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=3)", "modelString": "(length_scale=2)", "init_mode": "(length_scale=1)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=10)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=9)", "search": "(length_scale=7)", "normalised": "[[  1.99177695e-05   2.78848773e-04   3.98355391e-05   0.00000000e+00\n    2.98368188e-01   0.00000000e+00   8.59826613e-02   8.50132231e-02\n    5.43831792e-02   3.46250505e-03   4.17885049e-03   9.45182044e-01\n    1.99177695e-05]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=7)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=3)", "data_type": "(length_scale=8)", "loss": "(length_scale=2)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=8)", "activation2": "(length_scale=10)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=6)"}, "OU_student_pass.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=1)", "input_features": "(length_scale=10)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=1)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=3)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=6)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=10)", "search": "(length_scale=4)", "normalised": "[[  1.94584436e-05   2.14042880e-04   7.78337746e-05   1.94584436e-05\n    6.34209054e-01   5.62679815e-01   2.84653587e-01   3.10751345e-01\n    1.60582488e-01   2.78907602e-01  -2.58363440e-06  -2.05504132e-05\n    1.94584436e-05]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=1)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=4)", "data_type": "(length_scale=2)", "loss": "(length_scale=2)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=10)", "epochs": "(length_scale=8)", "activation2": "(length_scale=2)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=2)"}, "iris.data.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=7)", "hardware": "(length_scale=10)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=2)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=9)", "layers": "(length_scale=9)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=7)", "search": "(length_scale=6)", "normalised": "[[  6.65693890e-03   2.66277556e-02   1.99708167e-02   0.00000000e+00\n    9.98540835e-01   0.00000000e+00   2.30574174e-02   2.13022045e-02\n    1.31408040e-02   2.26335923e-02   8.50253765e-04  -6.97050440e-03\n    6.65693890e-03]]", "cpu_cores": "(length_scale=6)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=8)", "data_type": "(length_scale=1)", "loss": "(length_scale=3)", "score": "(length_scale=3)", "size_of_datasets": "(length_scale=3)", "optimiser": "(length_scale=10)", "epochs": "(length_scale=10)", "activation2": "(length_scale=2)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=7)"}, "yeast.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=10)", "input_features": "(length_scale=3)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=2)", "modelString": "(length_scale=2)", "init_mode": "(length_scale=9)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=8)", "output_features": "(length_scale=3)", "hidden_size": "(length_scale=4)", "search": "(length_scale=6)", "normalised": "[[  3.97501120e-04   3.57751008e-03   3.97501120e-03   3.97501120e-04\n    5.87904156e-01   6.26064264e-01   2.83691989e-01   2.59965732e-01\n    1.78754256e-01   2.86995809e-01  -4.69420080e-06  -4.03081886e-04\n    3.97501120e-04]]", "cpu_cores": "(length_scale=2)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=2)", "loss": "(length_scale=3)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=4)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=7)"}, "planning_relax.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=8)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=7)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=8)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=2)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=8)", "search": "(length_scale=4)", "normalised": "[[  5.48210578e-03   6.57852694e-02   1.09642116e-02   0.00000000e+00\n    9.97743252e-01   0.00000000e+00  -2.65321641e-05  -6.15169018e-06\n    2.27256649e-03   2.82786204e-03  -1.41592584e-03   3.90731238e-03\n    0.00000000e+00]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=1)", "weight_constraint": "(length_scale=10)", "dimensionality": "(length_scale=7)", "data_type": "(length_scale=8)", "loss": "(length_scale=4)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=2)"}, "digital_colposcopy_hinselmann.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=9)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=5)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=9)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=2)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=1)", "hidden_size": "(length_scale=3)", "search": "(length_scale=4)", "normalised": "[[ 0.00617027  0.4195785   0.01234054  0.          0.59851639  0.\n   0.29056182  0.02617855  0.39574281  0.47290988  0.00867989  0.00993407\n   0.        ]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=3)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=1)", "loss": "(length_scale=8)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=3)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=7)", "activation2": "(length_scale=1)", "activation1": "(length_scale=9)", "search_algorithm": "(length_scale=5)"}, "tic_tac_toe.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=9)", "input_features": "(length_scale=9)", "hardware": "(length_scale=1)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=8)", "modelString": "(length_scale=5)", "init_mode": "(length_scale=1)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=1)", "search": "(length_scale=2)", "normalised": "[[  1.04366067e-03   9.39294600e-03   2.08732133e-03   1.04366067e-03\n    9.99826919e-01   1.46112493e-02   3.89647841e-03   4.17464267e-03\n    1.62294326e-03   1.04366067e-03  -1.06174578e-03  -6.48453393e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=3)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=8)", "data_type": "(length_scale=7)", "loss": "(length_scale=8)", "score": "(length_scale=3)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=6)"}, "iris.data2.txt": {"learning_rate": "(length_scale=3)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=9)", "input_features": "(length_scale=5)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=5)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=8)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=7)", "hidden_size": "(length_scale=4)", "search": "(length_scale=2)", "normalised": "[[  1.11106598e-03   4.44426392e-03   3.33319794e-03   0.00000000e+00\n    9.99959381e-01   0.00000000e+00   3.84836220e-03   3.55541113e-03\n    2.19324534e-03   3.77762433e-03   1.41910275e-04  -1.16340114e-03\n    1.11106598e-03]]", "cpu_cores": "(length_scale=3)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=8)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=4)", "loss": "(length_scale=6)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=3)"}, "vertebral_column_2c.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=3)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=9)", "momentum": "(length_scale=3)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=9)", "layers": "(length_scale=10)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=4)", "search": "(length_scale=6)", "normalised": "[[  4.09462348e-04   3.27569878e-03   8.18924696e-04   4.09462348e-04\n    1.26933328e-01   7.42355237e-01   2.80841969e-01   2.49157839e-01\n    2.43865659e-01   4.82039549e-01   1.37086215e-04  -5.31907322e-04\n    4.09462348e-04]]", "cpu_cores": "(length_scale=6)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=7)", "data_type": "(length_scale=10)", "loss": "(length_scale=10)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=8)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=6)", "activation2": "(length_scale=2)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=3)"}, "phishing_websites.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=8)", "vocab_size": "(length_scale=1)", "input_features": "(length_scale=9)", "hardware": "(length_scale=2)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=3)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=7)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=4)", "search": "(length_scale=6)", "normalised": "[[  9.04564688e-05   2.71369407e-03   1.80912938e-04   0.00000000e+00\n    9.99996263e-01   0.00000000e+00   2.75076035e-05   9.04564688e-05\n    8.11637675e-05   1.80912938e-04  -5.74135226e-05  -1.31809358e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=3)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=4)", "data_type": "(length_scale=3)", "loss": "(length_scale=2)", "score": "(length_scale=4)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=4)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=7)", "search_algorithm": "(length_scale=9)"}, "wilt_train.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=9)", "input_features": "(length_scale=10)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=2)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=2)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=8)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=3)", "search": "(length_scale=3)", "normalised": "[[  2.29732526e-04   1.14866263e-03   4.59465052e-04   0.00000000e+00\n    9.96809431e-01   0.00000000e+00   4.76492788e-02   3.03246935e-02\n    4.44157185e-02   3.47319073e-02   3.35976352e-04   3.27398998e-04\n    2.29732526e-04]]", "cpu_cores": "(length_scale=7)", "batch_size": "(length_scale=3)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=1)", "loss": "(length_scale=10)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=8)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=9)", "search_algorithm": "(length_scale=8)"}, "pittsburgh_bridges.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=7)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=3)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=9)", "layers": "(length_scale=2)", "dropout_rate": "(length_scale=5)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=6)", "search": "(length_scale=7)", "normalised": "[[  2.13402212e-03   2.56082654e-02   1.70721769e-02   2.13402212e-03\n    2.30474389e-01   7.10629365e-01   4.08039519e-01   4.21469368e-01\n    1.88442592e-01   2.47546565e-01  -4.62732848e-04  -1.93754782e-03\n    2.13402212e-03]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=3)", "data_type": "(length_scale=2)", "loss": "(length_scale=8)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=6)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=5)", "search_algorithm": "(length_scale=9)"}, "diabetic_data.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=2)", "search_space": "(length_scale=9)", "vocab_size": "(length_scale=10)", "input_features": "(length_scale=5)", "hardware": "(length_scale=2)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=9)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=5)", "layers": "(length_scale=1)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=1)", "hidden_size": "(length_scale=2)", "search": "(length_scale=9)", "normalised": "[[  3.91629650e-06   1.91898529e-04   1.17488895e-05   3.91629650e-06\n    3.98545830e-01   6.82767132e-01   3.86134436e-01   4.40242639e-01\n    1.60806690e-01   7.88546301e-02  -3.26670408e-06   1.69086668e-06\n    3.91629650e-06]]", "cpu_cores": "(length_scale=2)", "batch_size": "(length_scale=9)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=9)", "loss": "(length_scale=4)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=3)", "epochs": "(length_scale=7)", "activation2": "(length_scale=6)", "activation1": "(length_scale=5)", "search_algorithm": "(length_scale=7)"}, "teaching_assistant_evaluation.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=2)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=2)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=5)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=8)", "output_features": "(length_scale=5)", "hidden_size": "(length_scale=1)", "search": "(length_scale=4)", "normalised": "[[ 0.00654598  0.03272991  0.01963794  0.          0.98844315  0.\n   0.06974288  0.01963794  0.0790009   0.09818972  0.01015574  0.01422388\n   0.00654598]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=4)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=10)", "loss": "(length_scale=7)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=1)"}, "breast-cancer-wisconsin-unformatted.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=8)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=10)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=6)", "momentum": "(length_scale=3)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=4)", "layers": "(length_scale=9)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=4)", "search": "(length_scale=5)", "normalised": "[[  4.33120224e-08   1.34267269e-06   8.66240448e-08   0.00000000e+00\n    2.46445408e-05   0.00000000e+00   4.24369633e-02   8.51947481e-09\n    9.99099144e-01   7.62820867e-07   1.59185435e-06   6.14059392e-05\n    0.00000000e+00]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=1)", "loss": "(length_scale=10)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=7)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=4)"}, "nursery.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=9)", "vocab_size": "(length_scale=10)", "input_features": "(length_scale=8)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=7)", "modelString": "(length_scale=2)", "init_mode": "(length_scale=4)", "layers": "(length_scale=4)", "dropout_rate": "(length_scale=10)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=4)", "search": "(length_scale=4)", "normalised": "[[  7.71597926e-05   7.71597926e-04   3.85798963e-04   7.71597926e-05\n    9.99990912e-01   3.16355150e-03   1.11675940e-03   8.48757719e-04\n    1.04277862e-03   2.08331440e-03   4.45302164e-05  -9.02890881e-05\n    7.71597926e-05]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=1)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=9)", "loss": "(length_scale=5)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=10)", "optimiser": "(length_scale=5)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=5)", "search_algorithm": "(length_scale=5)"}, "imports_85.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=2)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=1)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=6)", "modelString": "(length_scale=2)", "init_mode": "(length_scale=8)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=9)", "search": "(length_scale=5)", "normalised": "[[  9.61152984e-04   2.40288246e-02   1.79735608e-01   9.61152984e-04\n    1.97036362e-01   7.04525137e-01   3.82410421e-01   4.08490018e-01\n    1.87442303e-01   2.89307048e-01  -1.29049961e-04  -9.65357077e-04\n    9.61152984e-04]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=3)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=3)", "loss": "(length_scale=6)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=8)", "optimiser": "(length_scale=5)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=10)"}, "heart.txt": {"learning_rate": "(length_scale=7)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=2)", "vocab_size": "(length_scale=4)", "input_features": "(length_scale=3)", "hardware": "(length_scale=9)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=3)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=1)", "layers": "(length_scale=10)", "dropout_rate": "(length_scale=2)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=10)", "search": "(length_scale=3)", "normalised": "[[ 0.00342695  0.04455039  0.00685391  0.          0.92527733  0.\n   0.15776335  0.00685391  0.27057372  0.20870144  0.0061125   0.00885182\n   0.        ]]", "cpu_cores": "(length_scale=7)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=7)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=7)", "loss": "(length_scale=4)", "score": "(length_scale=4)", "size_of_datasets": "(length_scale=8)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=7)", "search_algorithm": "(length_scale=3)"}, "breast-cancer-wisconsin.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=5)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=6)", "momentum": "(length_scale=3)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=9)", "layers": "(length_scale=4)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=7)", "search": "(length_scale=4)", "normalised": "[[  8.79606665e-04   8.79606665e-03   1.75921333e-03   8.79606665e-04\n    6.14845059e-01   5.78781186e-01   2.93532546e-01   3.59759126e-01\n    1.51490565e-01   2.19901666e-01  -2.25192929e-04  -9.67920299e-04\n    8.79606665e-04]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=10)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=6)", "loss": "(length_scale=3)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=7)", "epochs": "(length_scale=8)", "activation2": "(length_scale=5)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=6)"}, "image_segmentation_statlog.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=1)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=10)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=1)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=7)", "search": "(length_scale=3)", "normalised": "[[  4.32664004e-04   8.22061608e-03   3.02864803e-03   0.00000000e+00\n    9.99453849e-01   0.00000000e+00   1.06578748e-02   9.91641538e-04\n    2.22629482e-02   1.08166001e-02   1.59557103e-03   1.68910474e-02\n    0.00000000e+00]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=4)", "dimensionality": "(length_scale=8)", "data_type": "(length_scale=5)", "loss": "(length_scale=1)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=7)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=5)", "search_algorithm": "(length_scale=5)"}, "biodeg.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=1)", "input_features": "(length_scale=3)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=6)", "momentum": "(length_scale=3)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=7)", "layers": "(length_scale=1)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=7)", "hidden_size": "(length_scale=9)", "search": "(length_scale=4)", "normalised": "[[  1.29966015e-04   5.45857265e-03   2.59932031e-04   1.29966015e-04\n    1.37114146e-01   8.56735973e-01   3.24074116e-01   1.84291810e-01\n    2.15039670e-01   2.48884919e-01   1.26353948e-04  -5.06600958e-05\n    0.00000000e+00]]", "cpu_cores": "(length_scale=2)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=1)", "dimensionality": "(length_scale=7)", "data_type": "(length_scale=4)", "loss": "(length_scale=5)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=7)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=4)"}, "turkiye-student-evaluation_generic.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=2)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=7)", "input_features": "(length_scale=4)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=2)", "modelString": "(length_scale=2)", "init_mode": "(length_scale=5)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=4)", "search": "(length_scale=6)", "normalised": "[[  1.71818457e-04   5.49819062e-03   8.59092285e-04   0.00000000e+00\n    9.99983419e-01   0.00000000e+00   5.44124070e-04   5.15455371e-04\n    2.82173775e-04   3.43636914e-04   2.42397971e-04   1.15991257e-03\n    0.00000000e+00]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=8)", "data_type": "(length_scale=4)", "loss": "(length_scale=3)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=10)", "epochs": "(length_scale=8)", "activation2": "(length_scale=2)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=4)"}, "activity_recognition_from_accelerometer.txt": {"learning_rate": "(length_scale=4)", "learning_tasks": "(length_scale=4)", "search_space": "(length_scale=9)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=1)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=6)", "momentum": "(length_scale=5)", "modelString": "(length_scale=10)", "init_mode": "(length_scale=1)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=2)", "search": "(length_scale=2)", "normalised": "[[  5.18881903e-07   2.59440952e-06   4.15105523e-06   0.00000000e+00\n    9.99831464e-01   0.00000000e+00   7.62352817e-03   1.06267014e-03\n    1.66648445e-02   2.81752873e-04   1.33212778e-06   2.98187317e-06\n    5.18881903e-07]]", "cpu_cores": "(length_scale=4)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=7)", "data_type": "(length_scale=6)", "loss": "(length_scale=5)", "score": "(length_scale=1)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=6)", "epochs": "(length_scale=2)", "activation2": "(length_scale=2)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=10)"}, "spam_base.txt": {"learning_rate": "(length_scale=7)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=9)", "input_features": "(length_scale=10)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=7)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=3)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=5)", "hidden_size": "(length_scale=3)", "search": "(length_scale=4)", "normalised": "[[  1.33680064e-04   7.61976365e-03   2.67360128e-04   0.00000000e+00\n    6.15061975e-01   0.00000000e+00   8.22235353e-04   0.00000000e+00\n    1.23620926e-02   0.00000000e+00   7.41695086e-03   7.88309653e-01\n    0.00000000e+00]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=7)", "dimensionality": "(length_scale=2)", "data_type": "(length_scale=1)", "loss": "(length_scale=9)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=8)"}, "wall_following_robot_sensors.txt": {"learning_rate": "(length_scale=10)", "learning_tasks": "(length_scale=2)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=1)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=1)", "modelString": "(length_scale=5)", "init_mode": "(length_scale=2)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=3)", "hidden_size": "(length_scale=1)", "search": "(length_scale=8)", "normalised": "[[  1.83282588e-04   4.39878211e-03   7.33130351e-04   0.00000000e+00\n    9.99989799e-01   0.00000000e+00   3.74958115e-04   2.83079957e-04\n    2.70129568e-04   3.42188592e-04   1.83140996e-04  -5.39811891e-05\n    1.83282588e-04]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=7)", "data_type": "(length_scale=7)", "loss": "(length_scale=3)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=2)", "optimiser": "(length_scale=5)", "epochs": "(length_scale=7)", "activation2": "(length_scale=7)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=8)"}, "liver_disorders.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=10)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=5)", "momentum": "(length_scale=3)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=9)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=5)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=8)", "search": "(length_scale=8)", "normalised": "[[ 0.00281206  0.01687236  0.00562412  0.          0.9701605   0.\n   0.12036429  0.08154972  0.09882934  0.16591151  0.00266462  0.00419358\n   0.00281206]]", "cpu_cores": "(length_scale=7)", "batch_size": "(length_scale=5)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=5)", "data_type": "(length_scale=10)", "loss": "(length_scale=6)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=6)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=6)"}, "vertebral_column_3c.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=3)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=6)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=10)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=2)", "layers": "(length_scale=4)", "dropout_rate": "(length_scale=2)", "output_features": "(length_scale=3)", "hidden_size": "(length_scale=8)", "search": "(length_scale=3)", "normalised": "[[  4.94585544e-04   8.40795424e-03   1.48375663e-03   4.94585544e-04\n    1.53321519e-01   9.00640275e-01   1.60144077e-01   0.00000000e+00\n    2.64444952e-01   2.63985034e-01   7.18240720e-04   3.25810849e-04\n    4.94585544e-04]]", "cpu_cores": "(length_scale=3)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=7)", "data_type": "(length_scale=7)", "loss": "(length_scale=1)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=10)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=8)"}, "UCI_HAR_test.txt": {"learning_rate": "(length_scale=3)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=5)", "hardware": "(length_scale=9)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=3)", "modelString": "(length_scale=9)", "init_mode": "(length_scale=4)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=6)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=9)", "search": "(length_scale=4)", "normalised": "[[  3.33341304e-04   1.87004471e-01   2.00004782e-03   0.00000000e+00\n    9.82356822e-01   0.00000000e+00  -1.69756331e-04  -2.33061313e-04\n    1.75198210e-04   2.89476205e-04   2.91789764e-04  -8.54593342e-05\n    0.00000000e+00]]", "cpu_cores": "(length_scale=4)", "batch_size": "(length_scale=3)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=4)", "loss": "(length_scale=9)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=3)", "activation2": "(length_scale=4)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=7)"}, "haberman_survival.txt": {"learning_rate": "(length_scale=10)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=1)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=2)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=1)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=6)", "output_features": "(length_scale=7)", "hidden_size": "(length_scale=7)", "search": "(length_scale=4)", "normalised": "[[ 0.00313125  0.00939376  0.00626251  0.          0.95816372  0.\n   0.12455774  0.16282521  0.0838217   0.18082992 -0.00165774 -0.00449945\n   0.00313125]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=8)", "loss": "(length_scale=4)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=10)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=8)"}, "indian_liver_patient.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=9)", "input_features": "(length_scale=1)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=8)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=9)", "layers": "(length_scale=4)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=10)", "search": "(length_scale=4)", "normalised": "[[  9.77118793e-04   9.77118793e-03   1.95423759e-03   9.77118793e-04\n    5.65751781e-01   5.83339919e-01   3.25607877e-01   3.48831409e-01\n    1.61390212e-01   2.92891358e-01  -2.73639260e-04  -1.11227655e-03\n    9.77118793e-04]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=3)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=2)", "data_type": "(length_scale=8)", "loss": "(length_scale=7)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=3)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=9)"}, "hepatitis.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=2)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=9)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=5)", "momentum": "(length_scale=1)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=8)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=8)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=9)", "search": "(length_scale=1)", "normalised": "[[  3.36339061e-03   6.39044215e-02   6.72678121e-03   3.36339061e-03\n    5.21325544e-01   6.89495074e-01   3.55676558e-01   3.09431936e-01\n    1.18589298e-01   1.10991890e-01  -2.12253769e-04   4.08097189e-03\n    3.36339061e-03]]", "cpu_cores": "(length_scale=2)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=2)", "data_type": "(length_scale=9)", "loss": "(length_scale=4)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=4)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=4)", "activation2": "(length_scale=6)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=3)"}, "jsbach_chorals_harmony.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=2)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=2)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=2)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=5)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=8)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=5)", "search": "(length_scale=2)", "normalised": "[[  1.75963141e-04   2.81541025e-03   1.79482404e-02   1.75963141e-04\n    9.96831192e-01   5.15572002e-02   3.06535673e-02   3.95917067e-02\n    1.31176341e-02   2.56906186e-02  -1.25977714e-04  -1.72016724e-04\n    1.75963141e-04]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=10)", "dimensionality": "(length_scale=8)", "data_type": "(length_scale=10)", "loss": "(length_scale=4)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=3)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=7)", "search_algorithm": "(length_scale=6)"}, "chess_king_rook.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=4)", "search_space": "(length_scale=2)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=6)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=3)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=7)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=1)", "hidden_size": "(length_scale=7)", "search": "(length_scale=8)", "normalised": "[[  3.56429702e-05   2.85143762e-04   6.41573464e-04   3.56429702e-05\n    9.99999172e-01   1.06928911e-03   6.57624615e-05   7.12859404e-05\n    5.95584070e-05   4.45537128e-05   2.97831692e-05  -7.15346667e-06\n    3.56429702e-05]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=4)", "data_type": "(length_scale=8)", "loss": "(length_scale=6)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=10)", "epochs": "(length_scale=3)", "activation2": "(length_scale=9)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=8)"}, "cylinder_bands.txt": {"learning_rate": "(length_scale=7)", "learning_tasks": "(length_scale=3)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=7)", "input_features": "(length_scale=3)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=9)", "momentum": "(length_scale=2)", "modelString": "(length_scale=2)", "init_mode": "(length_scale=9)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=3)", "search": "(length_scale=2)", "normalised": "[[  3.95348860e-04   1.54186055e-02   7.90697720e-04   3.95348860e-04\n    2.13488384e-01   6.93837249e-01   3.91869509e-01   4.08395372e-01\n    1.98573644e-01   3.36145368e-01  -7.62859951e-05  -4.59594403e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=2)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=3)", "data_type": "(length_scale=1)", "loss": "(length_scale=2)", "score": "(length_scale=6)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=7)", "search_algorithm": "(length_scale=1)"}, "post_operative_patient.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=2)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=7)", "input_features": "(length_scale=7)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=1)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=2)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=8)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=8)", "search": "(length_scale=6)", "normalised": "[[ 0.01075066  0.08600532  0.04300266  0.01075066  0.96755982  0.19351196\n   0.06964042  0.06450399  0.03840353  0.07794232  0.00143948 -0.01502595\n   0.01075066]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=5)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=1)", "loss": "(length_scale=6)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=2)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=9)", "activation2": "(length_scale=4)", "activation1": "(length_scale=1)", "search_algorithm": "(length_scale=4)"}, "letter_recognition.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=3)", "search_space": "(length_scale=9)", "vocab_size": "(length_scale=7)", "input_features": "(length_scale=8)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=5)", "momentum": "(length_scale=7)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=5)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=1)", "search": "(length_scale=3)", "normalised": "[[  4.99999716e-05   7.99999546e-04   4.99999716e-04   0.00000000e+00\n    9.99999433e-01   0.00000000e+00   2.96273113e-04   2.99999830e-04\n    1.45393223e-04   1.99999887e-04   3.78138471e-06  -1.70216173e-05\n    4.99999716e-05]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=8)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=5)", "loss": "(length_scale=7)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=6)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=5)"}, "congressional_voting.txt": {"learning_rate": "(length_scale=7)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=2)", "input_features": "(length_scale=3)", "hardware": "(length_scale=9)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=6)", "modelString": "(length_scale=5)", "init_mode": "(length_scale=6)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=10)", "output_features": "(length_scale=3)", "hidden_size": "(length_scale=1)", "search": "(length_scale=8)", "normalised": "[[ 0.00229666  0.03674649  0.00688997  0.00229666  0.9990452   0.01607659\n   0.01099788  0.00918662  0.00287017  0.00459331 -0.00195118  0.00184825\n   0.        ]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=7)", "weight_constraint": "(length_scale=7)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=4)", "loss": "(length_scale=9)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=4)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=1)"}, "credit_approval.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=2)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=5)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=10)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=7)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=3)", "hidden_size": "(length_scale=8)", "search": "(length_scale=8)", "normalised": "[[  6.55596014e-04   9.83394021e-03   1.31119203e-03   6.55596014e-04\n    4.52361250e-01   6.35272538e-01   3.50246881e-01   3.46810291e-01\n    1.87601830e-01   3.36976351e-01  -6.23840442e-05  -7.87200590e-04\n    6.55596014e-04]]", "cpu_cores": "(length_scale=6)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=7)", "dimensionality": "(length_scale=4)", "data_type": "(length_scale=6)", "loss": "(length_scale=4)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=8)", "activation2": "(length_scale=4)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=6)"}, "flags.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=4)", "search_space": "(length_scale=10)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=2)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=3)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=6)", "layers": "(length_scale=1)", "dropout_rate": "(length_scale=6)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=8)", "search": "(length_scale=5)", "normalised": "[[  1.93861191e-03   5.62197454e-02   1.55088953e-02   1.93861191e-03\n    3.76090711e-01   7.36672526e-01   3.77331891e-01   3.89660994e-01\n    1.26031539e-01   4.84652978e-02  -6.17437162e-04   2.94023780e-03\n    1.93861191e-03]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=7)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=8)", "loss": "(length_scale=5)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=10)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=5)", "search_algorithm": "(length_scale=7)"}, "annealing_test.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=3)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=9)", "momentum": "(length_scale=6)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=9)", "layers": "(length_scale=1)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=7)", "search": "(length_scale=2)", "normalised": "[[ 0.00557567  0.21187528  0.02230266  0.00557567  0.55756653  0.58544486\n   0.35534596  0.40144791  0.11248257  0.02787833 -0.0065524   0.00441811\n   0.        ]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=10)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=1)", "loss": "(length_scale=2)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=6)"}, "auto_mpg.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=2)", "vocab_size": "(length_scale=10)", "input_features": "(length_scale=7)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=5)", "modelString": "(length_scale=10)", "init_mode": "(length_scale=3)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=7)", "hidden_size": "(length_scale=7)", "search": "(length_scale=9)", "normalised": "[[  1.10202920e-03   3.96730512e-02   3.31710789e-01   1.10202920e-03\n    4.31995446e-01   8.08889432e-01   8.95722805e-02   0.00000000e+00\n    1.98555160e-01   2.75507300e-04   2.43874734e-03   4.00313778e-03\n    0.00000000e+00]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=7)", "dimensionality": "(length_scale=4)", "data_type": "(length_scale=4)", "loss": "(length_scale=10)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=9)"}, "banknote_authentication.txt": {"learning_rate": "(length_scale=10)", "learning_tasks": "(length_scale=3)", "search_space": "(length_scale=10)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=7)", "hardware": "(length_scale=2)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=3)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=2)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=2)", "search": "(length_scale=1)", "normalised": "[[  7.28850723e-04   2.91540289e-03   1.45770145e-03   0.00000000e+00\n    9.99983191e-01   0.00000000e+00   4.66839634e-04   1.72041569e-04\n    3.07255771e-03   3.39325565e-03   3.31347811e-04   7.85981703e-04\n    7.28850723e-04]]", "cpu_cores": "(length_scale=3)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=4)", "loss": "(length_scale=10)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=7)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=8)"}, "lung_cancer.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=9)", "input_features": "(length_scale=3)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=5)", "momentum": "(length_scale=7)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=8)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=4)", "search": "(length_scale=7)", "normalised": "[[ 0.01535449  0.85985168  0.03070899  0.01535449  0.49134382  0.10748146\n   0.05004777  0.04606348  0.01818773  0.03070899  0.00402322 -0.01082193\n   0.01535449]]", "cpu_cores": "(length_scale=8)", "batch_size": "(length_scale=9)", "weight_constraint": "(length_scale=4)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=4)", "loss": "(length_scale=8)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=7)", "activation2": "(length_scale=2)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=8)"}, "magic_gamma_telescope.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=7)", "hardware": "(length_scale=2)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=5)", "modelString": "(length_scale=9)", "init_mode": "(length_scale=7)", "layers": "(length_scale=1)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=9)", "search": "(length_scale=2)", "normalised": "[[  5.25757284e-05   5.25757284e-04   1.05151457e-04   0.00000000e+00\n    9.99990354e-01   0.00000000e+00   1.61290968e-03   4.38016280e-04\n    3.61671446e-03   1.73457712e-03   1.03217357e-04   3.29053242e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=7)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=4)", "data_type": "(length_scale=3)", "loss": "(length_scale=3)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=2)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=10)", "activation2": "(length_scale=2)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=2)"}, "steel_plate_faults.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=3)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=4)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=2)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=2)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=5)", "hidden_size": "(length_scale=7)", "search": "(length_scale=8)", "normalised": "[[  1.65488303e-06   5.46111400e-05   3.30976606e-06   0.00000000e+00\n    3.21212796e-03   0.00000000e+00   1.76158635e-01   1.65488303e-06\n    9.84356507e-01   1.65480360e-04   1.64374570e-05   2.30882177e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=5)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=3)", "data_type": "(length_scale=1)", "loss": "(length_scale=10)", "score": "(length_scale=3)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=6)", "activation2": "(length_scale=4)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=8)"}, "wiki4HE.txt": {"learning_rate": "(length_scale=7)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=3)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=2)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=10)", "modelString": "(length_scale=10)", "init_mode": "(length_scale=7)", "layers": "(length_scale=10)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=5)", "hidden_size": "(length_scale=1)", "search": "(length_scale=7)", "normalised": "[[  1.08763329e-03   5.65569310e-02   6.52579973e-03   1.08763329e-03\n    9.93009192e-01   7.83095967e-02   3.54585954e-02   1.95773992e-02\n    2.49636789e-02   4.78558647e-02   3.45218959e-04  -1.62434461e-03\n    0.00000000e+00]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=7)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=5)", "loss": "(length_scale=4)", "score": "(length_scale=6)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=2)", "activation2": "(length_scale=8)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=7)"}, "meta_data.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=1)", "hardware": "(length_scale=9)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=10)", "modelString": "(length_scale=5)", "init_mode": "(length_scale=3)", "layers": "(length_scale=4)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=4)", "search": "(length_scale=9)", "normalised": "[[  8.38181925e-04   1.76018204e-02   1.84400024e-02   8.38181925e-04\n    4.42560056e-01   6.74736450e-01   3.40288179e-01   3.54131863e-01\n    1.78580989e-01   2.74085490e-01  -4.53294212e-05  -7.79834413e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=8)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=9)", "loss": "(length_scale=5)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=10)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=7)"}, "ecoli.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=3)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=10)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=4)", "modelString": "(length_scale=5)", "init_mode": "(length_scale=1)", "layers": "(length_scale=9)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=4)", "search": "(length_scale=5)", "normalised": "[[  1.50773567e-03   1.20618853e-02   1.20618853e-02   1.50773567e-03\n    5.06599185e-01   6.60388223e-01   3.17793995e-01   3.18132226e-01\n    1.82544318e-01   2.67246147e-01   9.12958347e-05  -1.66942126e-03\n    1.50773567e-03]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=7)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=9)", "loss": "(length_scale=2)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=5)", "activation2": "(length_scale=4)", "activation1": "(length_scale=9)", "search_algorithm": "(length_scale=9)"}, "localisation.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=4)", "vocab_size": "(length_scale=1)", "input_features": "(length_scale=4)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=4)", "modelString": "(length_scale=10)", "init_mode": "(length_scale=9)", "layers": "(length_scale=4)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=1)", "hidden_size": "(length_scale=8)", "search": "(length_scale=7)", "normalised": "[[  1.16326660e-06   4.42041307e-05   1.27959326e-05   1.16326660e-06\n    1.91776131e-01   9.54531202e-01   8.33038270e-02   0.00000000e+00\n    2.12491342e-01   0.00000000e+00   3.02692617e-06   6.50520891e-06\n    0.00000000e+00]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=9)", "loss": "(length_scale=5)", "score": "(length_scale=1)", "size_of_datasets": "(length_scale=4)", "optimiser": "(length_scale=10)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=9)", "search_algorithm": "(length_scale=2)"}, "solar_flare1.txt": {"learning_rate": "(length_scale=7)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=10)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=2)", "hardware": "(length_scale=9)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=1)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=7)", "layers": "(length_scale=3)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=8)", "search": "(length_scale=8)", "normalised": "[[ 0.00308743  0.03704914  0.00617486  0.00308743  0.99723935  0.06174857\n   0.00853902  0.00926229  0.0047175   0.00926229  0.00158882  0.00129653\n   0.        ]]", "cpu_cores": "(length_scale=3)", "batch_size": "(length_scale=5)", "weight_constraint": "(length_scale=8)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=4)", "loss": "(length_scale=7)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=8)", "optimiser": "(length_scale=3)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=7)"}, "balance_scale.txt": {"learning_rate": "(length_scale=10)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=1)", "input_features": "(length_scale=9)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=9)", "modelString": "(length_scale=9)", "init_mode": "(length_scale=7)", "layers": "(length_scale=9)", "dropout_rate": "(length_scale=2)", "output_features": "(length_scale=5)", "hidden_size": "(length_scale=4)", "search": "(length_scale=9)", "normalised": "[[ 0.00159989  0.00639957  0.00479968  0.          0.99993256  0.\n   0.00479968  0.00479968  0.00226259  0.00319978  0.         -0.00207986\n   0.00159989]]", "cpu_cores": "(length_scale=6)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=8)", "dimensionality": "(length_scale=8)", "data_type": "(length_scale=7)", "loss": "(length_scale=5)", "score": "(length_scale=2)", "size_of_datasets": "(length_scale=3)", "optimiser": "(length_scale=3)", "epochs": "(length_scale=7)", "activation2": "(length_scale=2)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=2)"}, "winequality-red.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=4)", "search_space": "(length_scale=10)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=8)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=3)", "modelString": "(length_scale=9)", "init_mode": "(length_scale=7)", "layers": "(length_scale=9)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=7)", "search": "(length_scale=7)", "normalised": "[[  6.25209494e-04   6.87730444e-03   3.75125697e-03   0.00000000e+00\n    9.99709981e-01   0.00000000e+00   5.08559109e-03   1.37546089e-03\n    1.04575879e-02   5.52685193e-03   2.87192522e-03   1.85008796e-02\n    0.00000000e+00]]", "cpu_cores": "(length_scale=3)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=4)", "data_type": "(length_scale=5)", "loss": "(length_scale=3)", "score": "(length_scale=5)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=6)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=8)"}, "waveform_noise.txt": {"learning_rate": "(length_scale=4)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=4)", "input_features": "(length_scale=1)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=5)", "momentum": "(length_scale=1)", "modelString": "(length_scale=9)", "init_mode": "(length_scale=9)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=8)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=8)", "search": "(length_scale=3)", "normalised": "[[  1.99993522e-04   7.99974088e-03   5.99980566e-04   0.00000000e+00\n    9.99967610e-01   0.00000000e+00   1.79891813e-04   1.11996372e-04\n    3.51106435e-04   4.19986396e-04   1.68612294e-04   9.71049669e-05\n    0.00000000e+00]]", "cpu_cores": "(length_scale=7)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=1)", "dimensionality": "(length_scale=3)", "data_type": "(length_scale=7)", "loss": "(length_scale=8)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=4)", "optimiser": "(length_scale=3)", "epochs": "(length_scale=10)", "activation2": "(length_scale=2)", "activation1": "(length_scale=7)", "search_algorithm": "(length_scale=7)"}, "hayes_roth.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=7)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=8)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=9)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=5)", "layers": "(length_scale=8)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=1)", "search": "(length_scale=3)", "normalised": "[[ 0.00731794  0.03658972  0.02195383  0.          0.96596854  0.\n   0.10883778  0.01463589  0.22643045  0.01646537  0.01747763  0.03270618\n   0.00731794]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=7)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=2)", "data_type": "(length_scale=6)", "loss": "(length_scale=4)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=2)", "activation2": "(length_scale=2)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=6)"}, "seeds.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=10)", "search_space": "(length_scale=8)", "vocab_size": "(length_scale=4)", "input_features": "(length_scale=6)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=6)", "momentum": "(length_scale=8)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=5)", "layers": "(length_scale=2)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=3)", "hidden_size": "(length_scale=10)", "search": "(length_scale=1)", "normalised": "[[ 0.00474858  0.03324005  0.01424574  0.          0.99720151  0.\n   0.03274702  0.02472585  0.02528489  0.0434673   0.00393158 -0.00287675\n   0.00474858]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=3)", "data_type": "(length_scale=3)", "loss": "(length_scale=5)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=7)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=10)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=10)"}, "adult-test.txt": {"learning_rate": "(length_scale=10)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=7)", "input_features": "(length_scale=1)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=5)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=2)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=3)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=7)", "search": "(length_scale=7)", "normalised": "[[  4.07139460e-05   5.69995244e-04   8.14278921e-05   4.07139460e-05\n    6.62863755e-01   5.36487667e-01   2.74550227e-01   2.64111368e-01\n    1.64052199e-01   3.17405923e-01   6.16675981e-07  -5.29696830e-05\n    4.07139460e-05]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=7)", "weight_constraint": "(length_scale=4)", "dimensionality": "(length_scale=10)", "data_type": "(length_scale=4)", "loss": "(length_scale=1)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=9)", "activation2": "(length_scale=2)", "activation1": "(length_scale=5)", "search_algorithm": "(length_scale=10)"}, "drug_consumption.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=10)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=3)", "hardware": "(length_scale=1)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=3)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=3)", "layers": "(length_scale=10)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=5)", "hidden_size": "(length_scale=2)", "search": "(length_scale=9)", "normalised": "[[  2.64505811e-04   8.19968015e-03   1.85154068e-03   2.64505811e-04\n    4.98593454e-01   5.64190895e-01   3.86221029e-01   4.41989211e-01\n    1.56285874e-01   2.53132061e-01  -1.89623725e-04  -1.78901052e-04\n    2.64505811e-04]]", "cpu_cores": "(length_scale=6)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=1)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=1)", "loss": "(length_scale=2)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=4)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=9)"}, "transfusion.txt": {"learning_rate": "(length_scale=2)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=2)", "input_features": "(length_scale=8)", "hardware": "(length_scale=9)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=2)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=9)", "layers": "(length_scale=2)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=5)", "search": "(length_scale=4)", "normalised": "[[ 0.00079386  0.00317544  0.00158772  0.          0.59380784  0.\n   0.28340431  0.01270177  0.74483446  0.10478962  0.00418594  0.03350068\n   0.00079386]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=8)", "data_type": "(length_scale=10)", "loss": "(length_scale=5)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=4)", "optimiser": "(length_scale=5)", "epochs": "(length_scale=4)", "activation2": "(length_scale=2)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=8)"}, "digital_colposcopy_schiller.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=1)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=4)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=4)", "modelString": "(length_scale=1)", "init_mode": "(length_scale=7)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=4)", "search": "(length_scale=4)", "normalised": "[[ 0.00698945  0.47528288  0.01397891  0.          0.64302978  0.          0.2405\n   0.01710914  0.35266533  0.42089526  0.01216693  0.02383209  0.        ]]", "cpu_cores": "(length_scale=3)", "batch_size": "(length_scale=4)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=9)", "loss": "(length_scale=2)", "score": "(length_scale=4)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=3)", "epochs": "(length_scale=1)", "activation2": "(length_scale=2)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=3)"}, "skin.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=4)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=9)", "hardware": "(length_scale=2)", "fit_time": "(length_scale=7)", "momentum": "(length_scale=5)", "modelString": "(length_scale=3)", "init_mode": "(length_scale=6)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=4)", "search": "(length_scale=7)", "normalised": "[[  4.08068160e-06   1.22420448e-05   8.16136320e-06   0.00000000e+00\n    9.99999591e-01   0.00000000e+00   5.17906402e-04   5.59053379e-04\n    2.66367730e-04   4.08068160e-04  -1.22846356e-06  -3.21383076e-06\n    4.08068160e-06]]", "cpu_cores": "(length_scale=1)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=10)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=8)", "loss": "(length_scale=8)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=8)", "optimiser": "(length_scale=8)", "epochs": "(length_scale=3)", "activation2": "(length_scale=6)", "activation1": "(length_scale=4)", "search_algorithm": "(length_scale=7)"}, "connect4.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=10)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=3)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=4)", "momentum": "(length_scale=8)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=5)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=8)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=7)", "search": "(length_scale=2)", "normalised": "[[  1.48023119e-05   6.21697100e-04   4.44069357e-05   1.48023119e-05\n    9.99999786e-01   1.92430055e-04   2.88997518e-05   1.48023119e-05\n    2.97719775e-05   0.00000000e+00   2.59148034e-05   1.95477493e-05\n    0.00000000e+00]]", "cpu_cores": "(length_scale=4)", "batch_size": "(length_scale=7)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=3)", "data_type": "(length_scale=5)", "loss": "(length_scale=3)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=2)", "optimiser": "(length_scale=10)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=3)", "search_algorithm": "(length_scale=9)"}, "website_phishing.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=7)", "search_space": "(length_scale=5)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=6)", "hardware": "(length_scale=7)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=4)", "modelString": "(length_scale=7)", "init_mode": "(length_scale=2)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=1)", "output_features": "(length_scale=10)", "hidden_size": "(length_scale=7)", "search": "(length_scale=8)", "normalised": "[[  7.39078315e-04   6.65170483e-03   2.21723494e-03   0.00000000e+00\n    9.99972960e-01   0.00000000e+00   2.78588278e-05   0.00000000e+00\n    6.08846112e-04   1.47815663e-03  -5.16919222e-05  -1.12571008e-03\n    7.39078315e-04]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=2)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=6)", "data_type": "(length_scale=6)", "loss": "(length_scale=3)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=7)", "epochs": "(length_scale=8)", "activation2": "(length_scale=2)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=8)"}, "page_blocks.txt": {"learning_rate": "(length_scale=10)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=10)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=1)", "hardware": "(length_scale=10)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=4)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=7)", "layers": "(length_scale=10)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=1)", "search": "(length_scale=3)", "normalised": "[[  1.53348069e-04   1.53348069e-03   7.66740345e-04   0.00000000e+00\n    8.39273982e-01   0.00000000e+00   3.88472962e-02   1.84017683e-03\n    2.66532679e-01   1.69340739e-02   7.01067485e-03   4.71940824e-01\n    0.00000000e+00]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=1)", "weight_constraint": "(length_scale=1)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=6)", "loss": "(length_scale=10)", "score": "(length_scale=6)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=9)", "epochs": "(length_scale=10)", "activation2": "(length_scale=2)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=3)"}, "ionosphere.txt": {"learning_rate": "(length_scale=8)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=5)", "hardware": "(length_scale=8)", "fit_time": "(length_scale=8)", "momentum": "(length_scale=3)", "modelString": "(length_scale=2)", "init_mode": "(length_scale=5)", "layers": "(length_scale=2)", "dropout_rate": "(length_scale=5)", "output_features": "(length_scale=8)", "hidden_size": "(length_scale=3)", "search": "(length_scale=2)", "normalised": "[[  2.83565450e-03   9.64122531e-02   5.67130900e-03   0.00000000e+00\n    9.95314730e-01   0.00000000e+00   7.02383107e-04   3.78077815e-04\n    1.63234328e-03   2.39136415e-03  -1.04343440e-03  -1.71824954e-03\n    0.00000000e+00]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=5)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=7)", "loss": "(length_scale=4)", "score": "(length_scale=10)", "size_of_datasets": "(length_scale=4)", "optimiser": "(length_scale=4)", "epochs": "(length_scale=3)", "activation2": "(length_scale=2)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=8)"}, "mushrooms.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=2)", "hardware": "(length_scale=5)", "fit_time": "(length_scale=3)", "momentum": "(length_scale=9)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=6)", "layers": "(length_scale=1)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=2)", "hidden_size": "(length_scale=9)", "search": "(length_scale=8)", "normalised": "[[  1.23090970e-04   2.70800133e-03   8.61636787e-04   1.23090970e-04\n    9.99991036e-01   3.07727424e-03   3.03084171e-04   2.46181939e-04\n    2.80951732e-04   1.23090970e-04   2.12815085e-04   2.11646396e-04\n    1.23090970e-04]]", "cpu_cores": "(length_scale=6)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=2)", "data_type": "(length_scale=2)", "loss": "(length_scale=3)", "score": "(length_scale=7)", "size_of_datasets": "(length_scale=5)", "optimiser": "(length_scale=10)", "epochs": "(length_scale=6)", "activation2": "(length_scale=2)", "activation1": "(length_scale=10)", "search_algorithm": "(length_scale=8)"}, "adult-training.txt": {"learning_rate": "(length_scale=5)", "learning_tasks": "(length_scale=5)", "search_space": "(length_scale=4)", "vocab_size": "(length_scale=8)", "input_features": "(length_scale=6)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=9)", "modelString": "(length_scale=6)", "init_mode": "(length_scale=4)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=8)", "output_features": "(length_scale=3)", "hidden_size": "(length_scale=8)", "search": "(length_scale=1)", "normalised": "[[  2.29740865e-05   3.21637212e-04   4.59481731e-05   2.29740865e-05\n    7.48059232e-01   5.06785375e-01   2.14279122e-01   2.28638109e-01\n    1.57867766e-01   2.45891648e-01   6.20770884e-06  -2.65051191e-05\n    2.29740865e-05]]", "cpu_cores": "(length_scale=10)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=6)", "dimensionality": "(length_scale=5)", "data_type": "(length_scale=5)", "loss": "(length_scale=8)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=5)", "activation2": "(length_scale=2)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=6)"}, "winequality-white.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=3)", "search_space": "(length_scale=8)", "vocab_size": "(length_scale=9)", "input_features": "(length_scale=1)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=2)", "momentum": "(length_scale=5)", "modelString": "(length_scale=4)", "init_mode": "(length_scale=2)", "layers": "(length_scale=7)", "dropout_rate": "(length_scale=7)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=2)", "search": "(length_scale=9)", "normalised": "[[  2.04154628e-04   2.24570091e-03   1.42908239e-03   0.00000000e+00\n    9.99949367e-01   0.00000000e+00   3.76311837e-03   6.14505430e-04\n    8.48159332e-03   1.98438298e-03   6.19504307e-04   1.82724938e-03\n    0.00000000e+00]]", "cpu_cores": "(length_scale=9)", "batch_size": "(length_scale=8)", "weight_constraint": "(length_scale=2)", "dimensionality": "(length_scale=1)", "data_type": "(length_scale=2)", "loss": "(length_scale=6)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=6)", "optimiser": "(length_scale=5)", "epochs": "(length_scale=6)", "activation2": "(length_scale=4)", "activation1": "(length_scale=2)", "search_algorithm": "(length_scale=10)"}, "solar_flare2.txt": {"learning_rate": "(length_scale=1)", "learning_tasks": "(length_scale=9)", "search_space": "(length_scale=6)", "vocab_size": "(length_scale=3)", "input_features": "(length_scale=4)", "hardware": "(length_scale=4)", "fit_time": "(length_scale=5)", "momentum": "(length_scale=2)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=6)", "layers": "(length_scale=6)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=4)", "hidden_size": "(length_scale=2)", "search": "(length_scale=7)", "normalised": "[[  9.37783793e-04   1.12534055e-02   2.81335138e-03   9.37783793e-04\n    9.99677523e-01   2.15690272e-02   3.17198477e-03   1.87556759e-03\n    2.32808595e-03   4.68891897e-03   2.58380484e-04  -1.50377583e-03\n    0.00000000e+00]]", "cpu_cores": "(length_scale=3)", "batch_size": "(length_scale=10)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=8)", "loss": "(length_scale=7)", "score": "(length_scale=1)", "size_of_datasets": "(length_scale=1)", "optimiser": "(length_scale=4)", "epochs": "(length_scale=9)", "activation2": "(length_scale=2)", "activation1": "(length_scale=6)", "search_algorithm": "(length_scale=2)"}, "urban_land_cover_train.txt": {"learning_rate": "(length_scale=4)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=2)", "vocab_size": "(length_scale=9)", "input_features": "(length_scale=4)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=10)", "momentum": "(length_scale=2)", "modelString": "(length_scale=10)", "init_mode": "(length_scale=1)", "layers": "(length_scale=2)", "dropout_rate": "(length_scale=4)", "output_features": "(length_scale=9)", "hidden_size": "(length_scale=7)", "search": "(length_scale=2)", "normalised": "[[  8.02304682e-04   1.17938788e-01   7.22074213e-03   0.00000000e+00\n    1.34787187e-01   0.00000000e+00   2.41054919e-01   5.55194840e-03\n    9.38370783e-01   1.14061651e-01   8.06254824e-03   1.26952688e-01\n    0.00000000e+00]]", "cpu_cores": "(length_scale=5)", "batch_size": "(length_scale=1)", "weight_constraint": "(length_scale=9)", "dimensionality": "(length_scale=9)", "data_type": "(length_scale=1)", "loss": "(length_scale=3)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=8)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=6)", "activation2": "(length_scale=2)", "activation1": "(length_scale=7)", "search_algorithm": "(length_scale=2)"}, "OU_student_score.txt": {"learning_rate": "(length_scale=9)", "learning_tasks": "(length_scale=8)", "search_space": "(length_scale=1)", "vocab_size": "(length_scale=5)", "input_features": "(length_scale=2)", "hardware": "(length_scale=6)", "fit_time": "(length_scale=1)", "momentum": "(length_scale=7)", "modelString": "(length_scale=8)", "init_mode": "(length_scale=8)", "layers": "(length_scale=4)", "dropout_rate": "(length_scale=10)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=4)", "search": "(length_scale=7)", "normalised": "[[  2.07417765e-06   8.29671060e-06   2.11566120e-04   0.00000000e+00\n    3.60724384e-01   0.00000000e+00   3.79481465e-01   2.44752963e-03\n    8.48430559e-01   7.76613596e-02   7.67989205e-06   3.41607485e-05\n    2.07417765e-06]]", "cpu_cores": "(length_scale=7)", "batch_size": "(length_scale=5)", "weight_constraint": "(length_scale=3)", "dimensionality": "(length_scale=7)", "data_type": "(length_scale=4)", "loss": "(length_scale=4)", "score": "(length_scale=9)", "size_of_datasets": "(length_scale=3)", "optimiser": "(length_scale=2)", "epochs": "(length_scale=8)", "activation2": "(length_scale=4)", "activation1": "(length_scale=9)", "search_algorithm": "(length_scale=1)"}, "dermatology.txt": {"learning_rate": "(length_scale=6)", "learning_tasks": "(length_scale=6)", "search_space": "(length_scale=2)", "vocab_size": "(length_scale=6)", "input_features": "(length_scale=3)", "hardware": "(length_scale=3)", "fit_time": "(length_scale=6)", "momentum": "(length_scale=1)", "modelString": "(length_scale=9)", "init_mode": "(length_scale=2)", "layers": "(length_scale=5)", "dropout_rate": "(length_scale=9)", "output_features": "(length_scale=6)", "hidden_size": "(length_scale=3)", "search": "(length_scale=8)", "normalised": "[[  2.63328618e-03   8.95317300e-02   1.57997171e-02   2.63328618e-03\n    9.63782741e-01   1.73796888e-01   1.07034280e-01   1.34297595e-01\n    3.97040482e-02   3.94992926e-02  -3.03149158e-03  -2.52820390e-04\n    0.00000000e+00]]", "cpu_cores": "(length_scale=4)", "batch_size": "(length_scale=6)", "weight_constraint": "(length_scale=1)", "dimensionality": "(length_scale=8)", "data_type": "(length_scale=5)", "loss": "(length_scale=6)", "score": "(length_scale=8)", "size_of_datasets": "(length_scale=9)", "optimiser": "(length_scale=1)", "epochs": "(length_scale=9)", "activation2": "(length_scale=2)", "activation1": "(length_scale=8)", "search_algorithm": "(length_scale=3)"}}